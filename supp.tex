\documentclass[11pt]{article}

\usepackage{amssymb,amsmath,amsthm}
\usepackage{verbatim}
\usepackage{fullpage}
\usepackage{gencor}
\usepackage{mathrsfs}
\numberwithin{equation}{section}
\numberwithin{definition}{section}
\numberwithin{thm}{section}
\numberwithin{lemma}{section}
\numberwithin{prop}{section}
\numberwithin{cor}{section}
\numberwithin{hyp}{section}
\usepackage{graphicx}


\frenchspacing

%\setlength\parindent{0pt}`

\title{Supplementary Note to Estimating Genetic Correlation from GWAS Summary Statistics}
\author{Brendan Bulik-Sullivan}

\begin{document}
\maketitle
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Definitions}\label{Definitions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Let $y_1$ and $y_2$ denote phenotypes defined for individuals in a hypothetical population of infinite size 
(or more precisely, for individuals drawn from a distribution). 
Let $g$ denote a set of additively-coded SNPs, 
and let $g_1$ and $g_2$ denote the best linear predictors of $y_1$ and $y_2$ that can be constructed (at infinite sample size) from the SNPs in $S$\footnote
{Formally, the $g_i$ are constructed by projecting the phenotypes onto the vector space of functions $\{0,1,2\}^M\to\R$, where $M:=|g|.$
As a result $g_i$ may account for a large proportion of the variance in phenotype, 
even if in truth the way in which the phenotype is determined from genotype and environmental factors is completely non-additive.}.
Then we can write
\begin{align*}
	y_1 &= g_1 + \epsilon_1;\\
	y_2 &= g_2 + \epsilon_2,
\end{align*}
where $\epsilon_i$ denotes the residual, which is uncorrelated (in the population) with $g_i$ by the definition of a projection.
Note that so far this construction is applicable to arbitrary phenotypes\footnote{
Well, measurable finite-variance phenotypes. 
But this is no restriction at all on the genetic component, and hardly any restriction at all on the environmental component.}.

\begin{definition}\label{h2}
The narrow-sense (or additive) \textbf{heritability} of phenotype $y_i$ explained by the SNPs in $g$, 
denoted $h^2_g(y_i)$ is defined
\begin{equation}
h^2_g(y_i) := \corr[g_i,y_i]^2,
\end{equation}
\noindent
where $\corr$ denotes the correlation between random variables,
(alternatively, the correlation in a hypothetical population of infinite size),
not the empirical correlation in some finite sample.
\end{definition}

\begin{definition}  
The [additive] \textbf{genetic covariance} between $y_1$ and $y_2$ among SNP set $g$, 
denoted $\rho_g(y_1, y_2)$ is defined
\begin{equation}
\rho_g(y_1, y_2) := \frac{\cov[g_1,g_2]}{\sqrt{\var[y_1]\var[y_2]}}.
\end{equation}
\end{definition}

\begin{definition}  
The [additive] \textbf{genetic correlation} between $y_1$ and $y_2$ among SNP set $g$, 
denoted $r_g(y_1, y_2)$ is defined
\begin{equation}
r_g(y_1, y_2) := \dfrac{\gencov}{\sqrt{h^2_g(y_1)h^2_g(y_2)}}.
\end{equation}
\end{definition}

Note that these definitions make sense even when either or both phenotypes are binary,
and we refer to the specialization of definition \ref{h2} to a binary phenotype as 
the \textbf{\emph{heritability of the observed phenotype}}.

There are two challenges when dealing with binary phenotypes. 
The first is inferential:
often studies of binary phenotypes will over-sample cases in order to increase power.
Some work is required in order to obtain valid estimates of the parameters of a population with, say, 1\% cases 
from an ascertained sample with 50\% cases.
Ascertainment is addressed in section \ref{Conditional Expectation, Case/Control Traits}.
The second challenge is definitional: the heritability of the observed phenotype depends strongly on the prevalence of the
phenotype. 
For example, consider two liability threshold phenotypes $y_1$ and $y_2$, 
determined by the same underlying liability $\psi$, but with different thresholds. 
That is, $y_i := \mathbf{1}[\psi > \tau_i]$ for $i=1,2$.
Suppose $h^2_g(\psi)=1$, $\tau_1 = 0$ and $\tau_2 = 1.96$ 
(meaning the population prevalence of $y_1$ is 50\% and the population prevalence of $y_2$ is 5\%),
then the heritability of the observed phenotype $y_1$ is $0.64$,
and the heritability of the observed phenotype $y_2$ is $0.23$.

Sometimes it is desirable to compare the heritabilities or genetic covariances of phenotypes with different prevalences on an even footing,
and this is the primary application of liability-scale heritability and liability scale genetic covariance.
We note that one need not take the liability threshold model literally\footnote{We also note that the liability threshold model is (trivially) completely general. Let $y$ denote an arbitrary binary phenotype with prevalence $K$, and set $\tau := \Phi^-{1}(1-K)$, where $\Phi$ is the cdf of the standard normal distribution. We can construct a liability for $y$ as follows: if individual $i$ is a case, draw a liability $\psi_i$ from a truncated standard normal with left truncation point $\tau$. If individual $i$ is a control, draw a liability $\psi_i$ from a truncated standard normal with right truncation point $\tau$. Then $y=\mathbf{1}[\psi > \tau]$.}
in order for the conversion to the liability scale to be a useful procedure.
One can view this conversion simply as a tool for comparing phenotypes with different prevalences that is inspired by --
but not dependent on -- the liability threshold model.
An interpretation of LD Score regression under the liability threshold model is provided in section \ref{}.

There is no need to specify a scale when discussing genetic correlation. 
Genetic correlation on the observed scale is the same as genetic correlation on the liability scale is the same as genetic correlation in an ascertained sample.
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models}
\subsection{Quantitative Traits}\label{ctsmodel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Suppose we sample two cohorts for two phenotypes,
$y_1$ and $y_2$,
with sample sizes $N_1$ and $N_2$,
such that $N_s$ individuals are shared between cohorts and phenotyped for both traits.
We model phenotypes as generated by the equations
\begin{align*}
	y_1 &= Y\beta + \delta;\\
	y_2 &= Z\gamma + \epsilon,
\end{align*}
where $Y$ and $Z$ are matrices of genotypes normalized to mean zero and variance one\footnote{
We ignore the distinction between normalizing and centering in the population and in the sample, 
since this introduces only $\mathscr{O}(1/N)$ error.},
with dimensions $N_1\times M$ and $N_2\times M$, respectively; 
$\beta$ and $\gamma$ are $M\times 1$ vectors of per-normalized genotype effect sizes,
and $\delta$ and $\epsilon$ are vectors of environmental or non-additive genetic effects,
with dimensions $N_1\times 1$ and $N_2\times 1$, respectively.
In this model, $Y$ and $Z$ are unobserved matrices of \emph{all} SNPs,
unlike Yang, \emph{et al} \cite{yang2010}, 
we model the effects of SNPs that are not genotyped as well as those that are.

Now we introduce randomness:
we model all of $Y, Z, \beta, \gamma, \delta $ and $\epsilon$ as random variables.
Suppose that the $2M\times1$ vector $(\beta, \gamma)$ follows a distribution with mean zero and variance-covariance matrix\
\begin{equation*} 
	\var[(\beta, \gamma)] = \frac{1}{M}
		\left( \begin{array}{cc}
		\hsqo I & \gencov I\\
		\gencov I& \hsqt  I
	\end{array} \right),
\end{equation*}
and the $2N\times1$ vector $(\delta, \epsilon)$ follows a distribution with mean zero and variance-covariance matrix
\begin{equation*}
	\var[(\delta, \epsilon)] = 
		\left( \begin{array}{cc}
		(1-\hsqo) I & \envcov I\\
		\envcov I& (1-\hsqt) I
	\end{array} \right).
\end{equation*}
Finally suppose that each row (individual) of $Y$ and $Z$ 
represents an \emph{i.i.d.} draw from a distribution with covariance matrix (LD matrix) $R$
(except of course the $N_s$ rows that are duplicated in $Y$ and $Z$).
We will write $\E[Y_{ij}Y_{ik}] = R_jk =: r_jk$. 
Note that since we assume normalized genotypes,
$R$ is both the covariance matrix and correlation matrix. 
Additionally, note that under this model, $\var[y_1] = \var[y_2] = 1$. 
Let $\rho := \gencov + \envcov$ denote the covariance between $y_1$ and $y_2$,
which is also the correlation between $y_1$ and $y_2$, since both have variance one.

The assumption that all $\beta$ is drawn with equal variance for all SNPs is, of course, not reasonable.
We only make this assumption here for notational simplicity. 
In this paper, we use MAF- and LD-partitioned LD Score regression for estimation, as described in references \cite{finucane2014partitioning,buliksullivan2014kernel}.
This technique minimizes confounding under models where $\var[\beta]$ is correlated with MAF or LD Score.


\begin{prop} Under this model, the expected genetic covariance between phenotypes is $\gencov$, justifying our use of the notation $\gencov$.
\end{prop}
\begin{proof} Let $X$ denote an $1\times M$ vector of normalized, centered genotypes for an arbitrary individual. 
Under the model, the additive genetic component of $y_1$ for this individual is $\sum_j X_j\beta_j$,
and the additive genetic component of $y_2$ for this individual is $\sum_j X_j\gamma_j$.
Thus, the genetic covariance between $y_1$ and $y_2$ is 
$$\cov\left[\sum_{j=1}^M X_j\beta_j,\sum_{j=1}^M X_j\gamma_j\right],$$ 
\noindent
We can simplify this covariance with some algebra:
\begin{align*}
	\cov\left[\sum_{j=1}^M X_j\beta_j,\sum_{j=1}^M X_j\gamma_j\right] &= 
		\E\left[\left(\sum_{j=1}^M X_j\beta_j\right)\left(\sum_{j=1}^M X_j\gamma_j\right)\right]\\
		&= \E\left[ \sum_{j=1}^M \sum_{k=1}^M X_jX_j\beta_j\gamma_k\right]\\
		&= \E\left[ \sum_{j=1}^M X_j^2\beta_j\gamma_j \right]\\
		&= \sum_{j=1}^M \E[X_j^2]\E[\beta_j\gamma_j]\\
		&= \rho_g.
\end{align*}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Liability Threshold Model}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Suppose unobserved liability is generated following the usual model for quantitative traits:
\begin{equation*}
	\psi_i = \sum_{j=1}^M X_{ij}\beta_j + \epsilon_i.
\end{equation*}
The observed binary phenotype has population prevalence $K$, 
and is generated from the unobserved liability via the liability threshold model:
\[
	y_i := \ind[\psi_i > \tau],
\]
where $\tau:=\Phi^{-1}(1-K)$ is the liability threshold, and
$\Phi$ denotes the cdf of the standard normal distribution.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Derivations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Non-Ascertained Samples}
\subsubsection{Genetic Covariance}
\label{supp_condexp_qt}
Suppose we directly genotype SNP $j$. 
We estimate effect sizes using least-squares: 
\begin{align*}
	\bhat_j &:= \frac{1}{N_1}\T{Y}_jy_1;\\
	\chat_j &:= \frac{1}{N_2}\T{Z}_jy_2,
\end{align*}
where $Y_j$ and $Z_j$ denote the genotypes of all individuals at SNP $j$ 
and have dimensions $N_1\times 1$ and $N_2\times 1$, respectively.

\begin{prop} 
Under the model described in \ref{ctsmodel}, 
\begin{equation}
	\E[\bhat_j\chat_j] = \frac{\gencov}{M}\ell_j  + \frac{N_s\rho}{N_1N_2}.
\end{equation}
\end{prop}

\begin{proof} By the law of total expectation, 
$$\E[\bhat_j\chat_j] = \E[ \E[\bhat_j\chat_j \,|\, Y, Z ] ]$$
\noindent
First,
\begin{align*}
	\E[\bhat_j\chat_j\,|\,Y,Z] &= \frac{1}{N_1N_2}\E[\T{Y}_jy_1\T{y_2}Z_j]   \\
       		&= \frac{1}{N_1N_2}\T{Y}_j\E[{(Y\beta+\delta)}(Z\gamma+\epsilon)]Z_j\\
        		&= \frac{1}{N_1N_2}\T{Y}_j\left(Y\E[\beta\T{\gamma}]Z + \E[\T{\delta}\epsilon]\right)Z_j\\
        		&= \frac{1}{N_1N_2}\left( \frac{\gencov}{M} \T{Y}_jY\T{Z}_jZ  + \envcov\T{Y}_jZ_j  \right).
\end{align*}
\noindent
To remove the conditioning on $Y$ and $Z$, we need only compute 
$$\frac{1}{N_1N_2}\E[\T{Y}_jZ_j ] = \frac{N_s}{N_1N_2},$$ 
and 
$$\frac{1}{N_1N_2}\E[\T{Y}_jY\T{Z}_jZ] = \ell_j + \frac{MN_s}{N_1N_2}.$$
Thus, 
\begin{align*}
    \E[\bhat_j\chat_j] &= \frac{\gencov}{M}\ell_j  + \frac{N_s\rho}{N_1N_2}.
\end{align*}
Note that this expression does not contain any terms in which both the quantities $N_s$ and $\ell_j$ appear. 
In the special case where there are no overlapping samples shared between the two cohorts, this expression simplifies to 
\begin{equation*}
	\E[\bhat\chat] = \frac{\gencov}{M}\ell_j.
\end{equation*}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Regression Weights}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We can improve the efficiency of the LD Score regression by computing the conditional variance 
$\var[\bhat\chat \,|\,\ell_j]$
and weighting the regression by the reciprocal of this variance. 
In order to compute this conditional variance, 
we need further assumptions: in addition to the assumptions from \ref{ctsmodel}, 
assume that the phenotypes follow a multivariate normal distribution\footnote{
For instance, it is sufficient but not necessary to assume that $\beta$, $\gamma$, $\delta$ and $\epsilon$ are multivariate normal, 
and that $N_1$ and $N_2$ are sufficiently large that we can invoke the central limit theorem. 
More generally, the phenotypes will be approximately normal if $\delta$ and $\epsilon$ are normal 
and if $\beta$ and $\gamma$ are reasonably polygenic.
If there are few casual SNPs, then the conditional variance may be larger.}.

If phenotypes are normally distributed, then by the central limit theorem,
$\bhat$ and $\chat$ are jointly normally distributed with expectation zero. 
Thus,
\begin{align}
    \var[\bhat_j\chat_j\,|\,Y,Z] 
&= 
	\E[\bhat^2\chat^2]\nonumber\\
&=  
	\var[\bhat]\var[\chat]
	+
	2\E[\bhat\chat]^2\nonumber\\
&= 
	\left( 
		\frac{\hsqo\ell_j}{M} 
		+ 
		\frac{1}{N_1} 
	\right) \left(  
		\frac{\hsqt\ell_j}{M} 
		+ 
		\frac{1}{N_2}
	\right) 
	+ 					
	2\left( 
		\frac{\gencov\ell_j}{M} 
		+ 
		\frac{\rho N_s}{N_1N_2} 
	\right)^2.
\end{align}

Note that we only assume normality in order to compute regression weights.
If (quantitative) phenotypes are not normally distributed,
this will not affect the expectation of the LD Score regression estimates
(see \ref{supp_condexp_qt}, which makes no distributional assumptions about $\beta$ and $\gamma$ beyond first and second moments),
but will increase the standard error,
because in this case the regression weights will not be optimal for correcting for heteroskedasticity.
We never assume homoskedasticity when computing standard errors or $p$-values 
(we use a block jackknife, which is robust to heteroskedasticity), 
so non-normality of the phenotypes also does not bias our inference.
We derive regression weights for ascertained studies of binary phenotypes in section \ref{supp_condvar_cca}.
Note that if the phenotypes are normally distributed, then $\bhat_j\chat_j$
follows a product-normal distribution, which is not in the exponential family, so this is not a GLM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ascertainment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section, we derive the LD Score regression estimators of heritability and genetic covariance for ascertained case/control
samples (which was addressed only via simulation in \cite{buliksullivan2014}).
The fact that this estimator works is \emph{not} a consequence of the equivalence between LD Score regression and HE 
regression (see section \ref{LD Score Regression is Haseman-Elston Regression}),
and the fact that HE regression works in ascertained case/control samples \cite{golan2013narrowing},
because case/control ascertainment induces LD between causal SNPs in the ascertained samples. 
HE regression accounts for this LD by using a GRM computed from sample genotypes. 
It is not clear \emph{a priori} that the LD Score regression approach of using population LD as an estimate of sample LD
is valid when the sample is ascertained.
However, this turns out to be fine,
though we do not address this issue directly.
Our proof strategy is first to note that GWAS summary statistics can be written in terms of the sample allele frequencies in cases and the sample allele frequencies
in controls. 
Since the sample allele frequency in cases is a consistent estimator of the population allele frequency in cases, and likewise for the sample allele frequency in controls, 
we can write the large-$N$ limit of our GWAS summary statistics in terms of the population allele frequencies (see section \ref{CCA:Case/Control Test Statistics}).
Since the population allele frequencies depend on population LD rather than ascertained sample LD, LD Score regression with population LD yields a consistent
estimators of heritability and genetic covariance.

This section is structured as follows: 
in \ref{CCA:Heritability} and \ref{CCA:Genetic Covariance}, 
we show that using estimates of population LD is a valid, even with ascertained samples,
and we derive the usual factors for converting heritabilities and genetic covariances from ascertained samples into
estimates of the population heritabilities and genetic covariances.

In \ref{CCA:Liability Threshold Model}, we deal with the special case of the liability threshold model, and derive LD Score 
regression estimators of the heritability of liability, and genetic covariance between liability and other phenotypes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Case/Control Test Statistics}\label{CCA:Case/Control Test Statistics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Consider a study of size $N$ where the sample prevalence of phenotype $y$ is $P$. 
Let $N_{eff} := NP(1-P) = N_0N_1/N $ denote the effective sample size.
We compute $Z$-statistics
\begin{equation}
\label{z}
Z_j := 
\frac
	{\sqrt{N_{eff}}(\hat{p}_1 - \hat{p}_0)} 
	{\sqrt{\hat{p}_j(1-\hat{p}_j)}},
\end{equation}
and
$\chi^2$-statistics\footnote{
This is the equal to $N$ times the squared correlation between phenotype and genotype,
\emph{i.e.,} the Armitage Trend Test (ATT).}
\begin{equation}
\label{chisq}
	\chi^2_j := Z_j^2,
\end{equation}
where $\hat{p}_j$ denotes allele frequency in the entire sample\footnote{
Note that if $j$ has nonzero effect size, the expected value of $\hat{p}_j$ is not equal to $p_j$ 
unless $P=K$.},
$\hat{p}_1$ denotes allele frequency among cases in the sample
and $\hat{p}_0$ denotes allele frequency among controls in the sample.
We aim to derive an estimator of heritability from $\E[\chi^2_j\cond\ell_j]$ and an estimator of genetic covariance from $\E[Z_j\cond\ell_j]$ 
in samples where $P\neq K$ under various models of genetic architecture.
First, we need a lemma, which allows us to write our $\chi^2$-statistics in terms of population allele frequencies in the large-$N$ limit.

\begin{lemma}
In an ascertained study with sample size $N$, sample prevalence $P$ and population prevalence $K$, the expected $Z$-statistic of a SNP $j$
conditional on its population allele frequencies in cases and controls is
\begin{equation}
	\E[Z_j\cond p_0,p_1] =
\end{equation}
and the expected $\chi^2$ statistic is
\begin{equation}
	\E[\chi^2_j\cond p_0,p_1] = +1.
\end{equation}
\end{lemma}
\begin{proof}

Note that the case where we condition on $p_0$ and $p_1$ 
(\emph{i.e.,} when the only randomness is from sampling and genetic architecture is nonrandom),
is the usual case considered in power analyses for GWAS, so we can even obtain the asymptotic distributions of
the $Z$ and $\chi^2$ statistics from standard results on Wald statistics.
First,
\begin{equation*}
	Z_j\cond p_0, p_1 \sim N()
\end{equation*}
so
\begin{equation*}
	\E[Z_j\cond p_0,p_1] =
\end{equation*}
and $\chi^2_j$ follows a noncentral $\chi^2$ distribution with one degree of freedom and non-centrality parameter
\begin{equation*}
	\mathrm{NCP} =
\end{equation*}
Since the expected value of a noncentral $\chi^2$ distribution with $k$ degrees of freedom and noncentrality parameter $\lambda$ is 
$k+\lambda$,
\begin{equation*}
	\E[\chi^2_j\cond p_0, p_1] = +1
\end{equation*}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Heritability of the Observed Phenotype}\label{CCA:Heritability}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




Next, we remove the conditioning on $p_0$ and $p_1$ by noting that 
$p_0$ and $p_1$ are fixed conditional on $\beta_{loc}$,
and can be approximated using \ref{taylor1} and \ref{taylor2}.
Thus, the inner term of the numerator from \ref{totalexp} is
\begin{align}
\label{numerator2}
\notag
	\E[(\hat{p}_1 -\hat{p}_0)^2\cond\beta_{loc}]
\approx
	\dfrac{p_j^2\phi(\tau)^2\alpha_j^2}{K^2(1-K)^2}
&+
	\dfrac{p_j(1-p_j)
	+
	\dfrac{p_j\phi(\tau)\alpha_j}{K}\left(
	1 - 2p_j - \dfrac{p_j\phi(\tau)\alpha_j}{K}	
	\right)}{N_1}\\
&+	
	\dfrac{p_j(1-p_j)
	+
	\dfrac{p_j\phi(\tau)\alpha_j}{K}\left(
	2p_j -1 - \dfrac{p_j\phi(\tau)\alpha_j}{K}	
	\right)}{N_0}.\nonumber\\
&\approx
	 \dfrac{p_j^2\phi(\tau)^2\alpha_j^2}{K^2(1-K)^2} + \mathscr{O}(1/N).
\end{align}




Next, we remove the conditioning on $p_0$ and $p_1$. 
Let $C:=\phi(\tau)P(1-K) + K(1-P))/(K(1-K))$. 
Using the approximations from \ref{taylor1} and \ref{taylor2},
\begin{align*}
	\tilde{p}_j\cond\beta_{loc}
&\approx
	p_j\left(
		1 + C\alpha_j
	\right),
\end{align*}
and
\begin{align*}
	\E[\tilde{p}_j(1-\tilde{p}_j)\cond\beta_{loc}]
&=
	p_j(1 + C\alpha_j)(1-p_j-p_jC\alpha_j)\\
&=
	p_j\left(
		1-p_j+C\alpha_j(1-2p_j-p_jC\alpha_j).
	\right).
\end{align*}
Note that we have already computed $p_0(1-p_0)\cond\beta_{loc}$
and $p_1(1-p_1)\cond\beta_{loc}$ in \ref{numerator2}.
Thus, the inner term of the denominator of \ref{totalexp} is
\begin{align}
\label{denom}
\notag
	\E[\hat{p}_j(1-\hat{p}_j)\cond\beta_{loc}]
&= 
	p_j\left(
		1-p_j+C\alpha_j(1-2p_j-p_jC\alpha_j)
	\right)\\\notag
&-
	\dfrac{(1-P)^2p_j(1-p_j)
	+
	\dfrac{p_j\phi(\tau)\alpha_j}{K}\left(
	2p_j -1 - \dfrac{p_j\phi(\tau)\alpha_j}{K}	
	\right)}{N_0}\\
&-
	\dfrac{P^2p_j(1-p_j)
	+
	\dfrac{p_j\phi(\tau)\alpha_j}{K}\left(
	1 - 2p_j - \dfrac{p_j\phi(\tau)\alpha_j}{K}	
	\right)}{N_1}\nonumber\\
&\approx
	p_j\left(
		1-p_j+C\alpha_j(1-2p_j-p_jC\alpha_j)
	\right) + \mathscr{O}(1/N).
\end{align}

We now introduce randomness into $\beta$. 
For this section, model the entries of $\beta$ as \emph{i.i.d.} draws 
from a distribution with expectation zero and variance $h^2/M$.
The heritability of liability (in the population) under this model is $h^2$; 
$\E[\alpha_j]=0$;
$\E[Z_j]=0$, and 
\[
	\E[\alpha_j^2] = \frac{(1-p_j)h^2}{p_jM}\ell_j.
\]
The expected numerator of the $\chi^2$-statistic is therefore
\begin{align*}
	N_{eff}\E[(\hat{p}_1 - \hat{p}_0)^2]
&=
	p_j(1-p_j)\left(\dfrac{N_{eff}\phi(\tau)^2h^2\ell_j}{K^2(1-K)^2M}
	\left(
		1
		+
		\dfrac{N(1-K)^2}{N_0N_1K^2}
	\right)
	+
	\dfrac{NN_{eff}}{N_0N_1}
	\right)\\
&\approx
	p_j(1-p_j)\left(\dfrac{N_{eff}\phi(\tau)^2h^2\ell_j}{MK^2(1-K)^2}
	+
	1\right),
\end{align*}
where the approximation is justified by the fact that $N/N_0N_1 \ll1$,
which is a reasonable approximation when $P$ is not so far from $1/2$ (a balanced study).
For brevity, let $c$ denote
\[
	c := \dfrac{P(1-P)\phi(\tau)^2}{K^2(1-K)^2},
\]
which is the factor used to convert between liability scale heritability, $h^2$ and observed scale heritability, $h^2_{obs} := ch^2$.

The expected denominator of the $\chi^2$-statistic is 
\begin{align*}
	\E[\hat{p}_j(1-\hat{p}_j)]
&=
	p_j(1-p_j) -\mathscr{O}(\ell_j/M)+\mathscr{O}(1/N)\\
&\approx
	p_j(1-p_j).
\end{align*}
Thus,
\begin{align}
	\E[\chi^2_j]
&\approx
	c\dfrac{Nh^2}{M}\ell_j+1\nonumber\\
&=
	\dfrac{Nh^2_{obs}}{M}\ell_j+1.
\end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Genetic Covariance with the Observed Phenotype}\label{CCA:Genetic Covariance}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section, we derive a genetic covariance estimator that works when both studies are ascertained to oversample cases and may include overlapping samples.
This derivation does not cover more complicated ascertainment schemes 
(\emph{e.g.,} attempting to estimate genetic covariance between T2D and BMI from a T2D GWAS consisting of low-BMI cases 
and high-BMI controls).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Heritability and Genetic Covariance of Liability}\label{CCA:Liability Threshold Model}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For phenotypes generated according to the liability threshold model, we can estimate not only the heritability of the observed
phenotype (genetic covariance between the observed phenotype and other phenotypes), but also the heritability of the 
unobserved liability (genetic covariance between unobserved liability and other phenotypes).

The derivation is the same as in \ref{CCA:Heritability} and \ref{CCA:Genetic Covariance}, except with one extra step: 
we need to write $\prob[y_i=1\cond G_{ij}=1]$ in terms of the heritability of liability.

Let $\alpha_j:=\E[\psi\cond G_{ij}=1] = p_j^{-\frac{1}{2}}(1-p_j)^{\frac{1}{2}}\sum_{\{k\cond r_{jk} \neq 0\}} r_{jk}\beta_k$ 
denote the marginal per-normalized genotype effect size of SNP $j$ on liability.
This is the per-normalized-genotype effect size that one would obtain from regressing liability against the genotype at SNP $j$
at infinite sample size.

Then if $\phi(x,\mu,\sigma^2)$ denotes the density of a normal distribution
with expectation $\mu$ and variance $\sigma^2$ evaluated at $x$,
\begin{align*}
	\prob[y_i=1\cond G_{ij}=1] 
&= 
	\int_{\tau}^\infty \phi(x,\alpha_j,1-\alpha_j^2)dx\\
&=
	\int_{\tau-\alpha_j}^\infty \phi(x(1-\alpha_j^2)^{\frac{1}{2}};0,1)dx\\
&= % u = x\sqrt{1-\alpha_j^2}
	(1-\alpha_j^2)^{-\frac{1}{2}}\int_{(\tau-\alpha_j)(1-\alpha_j^2)^{\frac{1}{2}}}^\infty \phi(u;0,1)du\\
&= 
	(1-\alpha_j^2)^{-\frac{1}{2}}(1 - \Phi(\tau')),
\end{align*}
where $\tau' := (\tau-\alpha_j)(1-\alpha_j^2)^{\frac{1}{2}}$. 
Similarly,
\begin{align*}
	\prob[y_i=0\cond G_{ij}=1] 
&= 
	1-\prob[y_i=1\cond G_{ij}=1] \\
&=	
	1 - (1-\alpha_j^2)^{-\frac{1}{2}}(1 - \Phi(\tau')).
\end{align*}

We approximate $\Phi(\tau')$ with a first-order Taylor expansion\footnote{
This is a reasonable approximation for small $\alpha_j$, \emph{e.g.,} for polygenic traits
and away from loci with huge effects.}
around $\tau$:
\begin{align*}
	\Phi(\tau') 
&\approx 
	\Phi(\tau) + \phi(\tau)(\tau'-\tau)\\
&=
	1-K + \phi(\tau)(\tau'-\tau).
\end{align*}
We also make the approximation that
$$(1-\alpha_j^2)^{\frac{1}{2}}\approx 1.$$
Thus we have
\begin{align}
\label{taylor1}
\notag
	p_1\cond\beta_{loc} 
&= 
	\dfrac{p_j}{K}(1-\alpha_j^2)^{-\frac{1}{2}}(1 - \Phi(\tau'))\\
&\approx
	p_j\left(1+\frac{\phi(\tau)\alpha_j}{K}\right),
\end{align}
and
\begin{align}
\label{taylor2}
\notag
	p_0\cond\beta_{loc} 
&=  
	\frac{p_j}{1-K}\left(
		1 - (1-\alpha_j^2)^{-\frac{1}{2}}(1 - \Phi(\tau'))
	\right)\\
&\approx
	p_j\left(1 - \frac{\phi(\tau)\alpha_j}{1-K}\right).
\end{align}

We can plug these results into the expressions from \ref{CCA:Heritability} in order to obtain an estimator of the heritability
of liability:
 
 WRITE MEEEE

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Regression Weights}\label{CCA:Regression Weights}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Lorem Ipsum Dolor Sic Amet


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Supplementary Figures}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Comparison of Metabolic Genetic Correlations from LDSC to Results from Vattikuti, et al}
\begin{figure}[!ht]

\begin{centering}
%\caption{S}
    \includegraphics[scale=0.8]{figs/vattikuti.pdf}
         \label{vattikuti}

This figure compares the estimates of genetic correlations between metabolic traits from table 3 of \cite{vattikuti2012heritability}
to the results obtained using roughly 10x larger sample sizes and LD Score regression in this paper.
\end{centering}
\end{figure}
\newpage


\subsection{Linkage Disequilibrium May Create False Positive Pleiotropy}
\begin{figure}[!ht]

\begin{centering}
%\caption{S}
    \includegraphics[scale=0.8]{figs/infinitesimal_sim.pdf}
         \label{pleiotropy}


Conditional QQ plot from two completely independent simulated phenotypes with phenotypes generated according to the 
infinitesimal model ($y=X\beta + \epsilon$ with $\beta$ and $\epsilon$ drawn from normal distributions). 
The two phenotypes were independent with zero genetic correlation, but the conditional QQ plots show substantial enrichment
(\emph{i.e.,} the light blue line is well above the dark blue line), 
and the correlation between log $p$-values was $0.14$. 
This effect can be explained by the tendency for $p$-values to be lower at SNPs with high LD Score noted in 
\cite{buliksullivan2014}. 
The set of SNPs with $p$-values for trait 1 below some threshold is enriched for SNPs with high LD Scores,
which will tend to have lower $p$-values for trait 2 as well. 

\end{centering}
\end{figure}
\newpage

\subsection{Pleiotropy Between Triglycerides and Schizophrenia may be Confounded by LD}
\begin{figure}[!ht]

\begin{centering}
%\caption{S}
    \includegraphics[scale=0.6]{figs/qq_TG.pdf}
         \label{qq_tg}

We reproduced the conditional QQ plot comparing schizophrenia (SCZ) and triglycerides (TG) from \cite{andreassen2013improved} (left).
We then residualized the TG $p$-values on LD Score and plotted a new conditional QQ-plot (right). 
Residualizing on LD Score removed almost all of the enrichment, which is consistent with the 
near-zero genetic correlation between schizophrenia and TG estimated via LD Score regression.

\end{centering}
\end{figure}
\newpage


\subsection{Pleiotropy Between Bipolar and Schizophrenia Remains after Correction for LD}
\begin{figure}[!ht]

\begin{centering}
%\caption{S}
    \includegraphics[scale=0.6]{figs/qq_BIP.pdf}
         \label{qq_bip}
         
As a positive control, we performed the same experiment from the previous figure with schizophrenia (SCZ) and 
bipolar disorder (BIP), which have a strong positive genetic correlation. 
In this case, the conditional QQ plot continued to show signal of pleiotropy 
after residualizing the BIP $p$-values on LD Score.

\end{centering}
\end{figure}
\newpage




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Supplementary Tables}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Simulations with Parallel LD- and MAF-Dependence}
\label{parallel}
\input{./table/parallel_arch_sim}
This table displays simulations with MAF- and LD-dependent genetic architecture where the MAF- and LD- dependence was the same for both phenotypes and genetic correlation did not vary with MAF or LD. Precisely, effect sizes were drawn from a normal distribution so that the magnitude of per-allele effect sizes were uncorrelated with MAF and variants with LD Score below 100 were $4\times$ enriched for heritability.

In all simulations, the sample size was 2062 individuals with full sample overlap between studies; the causal SNPs were best-guess imputed 1000 Genomes SNPs on chromosome 2, and the SNPs retained for the LD Score regression were HapMap 3 SNPs. 

Estimates are averages across 100 simulations. Standard deviations (in parentheses) are calculated as the empirical standard deviation across 100 simulations.

LD Scores were estimated using in-sample LD and a 1cM window. 
HM3 LD Score is $\sum r^2$ with the sum taken over SNPs in HapMap 3. 
The PNG LD Score is $\sum r^2$ with the sum taken over all SNPs in 1kG as in \cite{buliksullivan2014}. The 30 bins LD Score is a per-allele LD Score binned on a MAF by LD Score grid with MAF breaks at 0.05, 0.1, 0.2, 0.3 and 0.4 and LD Score breaks at 35, 75, 150 and 400. The 60 bins LD Score is a per-allele LD Score binned on a MAF by LD Score grid with MAF breaks at 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4 and 0.45 and LD Score breaks at 30, 60, 120, 200 and 300

These simulations demonstrate that naive LD Score regression can give accurate genetic correlation estimates even in situations where the heritability and genetic covariance estimates are badly biased, so long as genetic correlation does not depend on MAF or LD. In addition, these simulations demonstrate that MAF- and LD-binned LD Score regression can give accurate estimates of heritability and genetic covariance even for genetic architectures with MAF- and LD-dependence.

\newpage
\subsection{Simulations with Antiparallel LD- and MAF-Dependence}
\label{antiparallel}
\input{./table/antiparallel_arch_sim}
This table displays simulations with MAF- and LD-dependent genetic architecture where the MAF- and LD- dependence was in opposite directions for each phenotype, and genetic correlation did not vary with MAF or LD. Precisely, per-allele effect sizes for the first phenotype were drawn from a normal distribution so that the variance of per-allele effect sizes were uncorrelated with MAF, and variants with LD Score below 100 were $4\times$ enriched for heritability. Per-allele effect sizes for the second phenotype were drawn from a normal distribution so that the variance of per-allele effect size followed $\sqrt{p(1-p)}$, where $p$ is MAF, and variants with LD Score above 100 were $4\times$ enriched for heritability. Otherwise, the parameters of these simulations were the same as in \ref{parallel}
These simulations demonstrate that naive LD Score regression can give approximately accurate genetic correlation estimates even in situations where the heritability and genetic covariance estimates are badly biased, so long as genetic correlation does not depend on MAF or LD. In addition, these simulations demonstrate that MAF- and LD-binned LD Score regression can give accurate estimates of heritability and genetic covariance even for genetic architectures with MAF- and LD-dependence.
\newpage
\subsection{Simulations with LD- and MAF-Dependent Genetic Correlation}
\label{depcor}
\input{./table/gencor_dep_sim}

In these simulations, effect sizes for the first phenotype were drawn from a normal distribution with mean zero and variance
$(pq)^{0.6}(1+\mathrm{log}(\ell_j)/50)^2$, 
effect sizes for the second phenotype were drawn form a normal distribution with mean zero and variance
$(pq)^{0.3}(1-\mathrm{log}(\ell_j)/50)^2$,
then noise following a normal distribution with mean zero and variance 
$ 1+(7-1)\ell_j/700$,
was added to the effect sizes for the second phenotype, so that genetic correlation was roughly 0.35 for low LD SNPs and 
0.65 for high LD SNPs.   

%\input{./table/gencor_dep_sim_caption}


\newpage
\subsection{Comparison of Standard Error Estimates to Empirical Standard Deviation across Simulations}
\label{se_sim}
\input{./table/parallel_arch_sim_se}
This table compares the block jackknife standard errors from ldsc (denoted $\widehat{se}$, which represents the mean standard error estimate across 100 simulation replicates) in the simulations from \ref{parallel} to the empirical standard deviations of the parameter estimates (denoted $sd$) across 100 simulation replicates. The block jackknife standard errors closely match the empirical standard deviations. This confirms that block jackknife standard error estimates are approximately unbiased even with locally correlated error terms, so long as the block size is sufficiently large.
\newpage
\subsection{Comparison of BMI-Adjusted WHR Genetic Correlations from LDSC to Unadjusted WHR from Vattikuti, et al}
\label{whr}
\input{./table/whr}

This table contrasts the genetic correlation profiles of waist-hip ratio (WHR) and BMI-adjusted WHR.
In this paper, we estimated genetic correlations with BMI-adjusted WHR using the summary statistics from \cite{heid2010meta}.
Vattikuti \emph{et. al.} \cite{vattikuti2012heritability}
estimated genetic correlations between unadjusted WHR and other metabolic traits using REML. 
The genetic correlation profiles of these two phenotypes are quite dissimilar, especially with regards to BMI.




%\newpage
%\subsection{300 Genetic Correlations}
%\label{300 gencors}
%\input{./table/300_gencors}


%\newpage
%\subsection{Summary Statistic Metadata}


\newpage
\bibliographystyle{plain}
\bibliography{gencor}

\end{document}